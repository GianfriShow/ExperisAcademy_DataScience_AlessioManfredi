{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 7], 'criterion': ['gini', 'entropy']}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)  # exhaustive grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# PARAMETERS:\n",
    "# estimator --> model to optimize\n",
    "# param_grid --> dictionary with parameters and values to test\n",
    "# cv --> number of folds for cross-validation\n",
    "# scoring --> strategy for evaluating the model\n",
    "# n_jobs --> number of parallel processes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='rbf', C=1))])  # sequentially run some processes\n",
    "\n",
    "param_grid = {'svc__C': [0.1, 1, 10], 'svc__kernel': ['linear', 'rbf']}  # use the name of the process followed by '__' and the parameter name\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# PARAMETERS:\n",
    "# list of tuples: (process_name, transformation_or_estimator)\n",
    "# each name must be unique and without a final underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_classification()\n",
    "\n",
    "# PARAMETERS:\n",
    "# n_samples --> total number of samples\n",
    "# n_features --> total number of features\n",
    "# n_informative --> number of informative features\n",
    "# random_state --> seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC()  # Support Vector Classification\n",
    "\n",
    "# PARAMETERS:\n",
    "# C --> regularization parameter\n",
    "# kernel --> kernel type ('linear', 'poly', 'rbf', 'sigmoid')\n",
    "# gamma --> kernel coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)\n",
    "\n",
    "# stratify --> if y, maintains class proportions in the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('pca', PCA()), ('gbc', GradientBoostingClassifier(random_state=123))])\n",
    "\n",
    "# standardize -> apply PCA -> apply gradient boosting classifier, a classification model based on boosting and ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'pca__n_components': sp_randint(5, 13),  # integer distribution between 5 (inclusive) and 13 (exclusive)\n",
    "    'gbc__n_estimators': sp_randint(50, 200),\n",
    "    'gbc__learning_rate': uniform(0.01, 0.2),  # uniform distribution [0.01, 0.01+0.2]\n",
    "    'gbc__max_depth': sp_randint(1, 5),\n",
    "    'gbc__subsample': uniform(0.6, 0.4),\n",
    "    'gbc__min_samples_split': sp_randint(2, 10),\n",
    "    'gbc__min_samples_leaf': sp_randint(1, 10),\n",
    "    'gbc__max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# PARAMETERS:\n",
    "# PCA\n",
    "#   n_components --> number of principal components to keep\n",
    "# GradientBoostingClassifier\n",
    "#   n_estimators --> number of boosting rounds\n",
    "#   learning_rate\n",
    "#   max_depth --> maximum depth for each tree\n",
    "#   subsample --> percentage of samples to use for each tree\n",
    "#   min_samples_split --> minimum samples required to split a node\n",
    "#   min_samples_leaf --> minimum samples required in each leaf (result of splitting a node)\n",
    "#   max_features --> maximum number of features to consider when planning the next split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)  # configure the cross-validation splitter, ensuring class proportions are maintained\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=50, cv=cv, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "\n",
    "# PARAMETERS:\n",
    "# pipeline --> a previously-defined pipeline of processes\n",
    "# param_distributions --> dictionary of parameters to search\n",
    "# n_iter --> number of combinations of parameters to sample and test\n",
    "# cv --> cross-validation method\n",
    "# scoring --> performance metric to report\n",
    "# random_state --> seed\n",
    "# n_jobs --> number of cores to use for parallel computation; if -1, it will use all cores available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 4.39988248e-01  9.15770358e-03 -1.11827735e-01  6.47857908e-01\n",
      " -6.55068105e-06 -3.92330215e-03 -4.17033805e-01 -4.27676550e-01]\n",
      "Intercept: -36.25561939898517\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "# PARAMETER:\n",
    "# fit_intercept: (default True) --> if True, it will include an intercept\n",
    "# normalize: (deprecated) --> if you need to standardize, do it BEFORE regressing\n",
    "# copy_X: (default True) --> if True, it will copy the input data, otherwise it will overwrite it\n",
    "# n_jobs --> number of cores to use for parallel computation; if -1, it will use all cores available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
